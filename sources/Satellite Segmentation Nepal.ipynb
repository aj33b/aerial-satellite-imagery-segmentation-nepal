{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Satellite Image Segmentation of Nepal\n",
    "**Prepared By:** Ajeeb Rimal | M. Tech. AI | Kathmandu University"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Directory definitions and setup\n",
    "We have defined the directory paths for the dataset, image, and mask files. We have also defined and created the output directory where the patches will be saved.Additionally we have defined the patch size, stride, and boundary for the patches. The boundary is defined as a list of four values: [min_x, min_y, max_x, max_y] which represent the minimum and maximum x and y coordinates of the area of interest, respectively. We have used the `os` library to create the output directory if it does not exist."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:27.665877Z",
     "start_time": "2025-02-16T14:34:27.490611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:27.992575Z",
     "start_time": "2025-02-16T14:34:27.949796Z"
    }
   },
   "cell_type": "code",
   "source": "import os",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:28.603368Z",
     "start_time": "2025-02-16T14:34:28.559725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mission_list = [\"Mission 1\", \"Mission 2\", \"Mission 3\", \"Mission 4\", \"Mission 5\"]\n",
    "dataset_dir = r\"/Users/ajeebrimal/Documents/Masters Thesis/Datasets/Rupandehi Data\"\n",
    "annotations_dir = os.path.join(dataset_dir, \"Annotations\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:29.060923Z",
     "start_time": "2025-02-16T14:34:29.021709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = r\"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "rasterized_dir = os.path.join(output_dir, \"rasterized_outputs\")\n",
    "os.makedirs(rasterized_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:29.792764Z",
     "start_time": "2025-02-16T14:34:29.748713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_dir = os.path.join(dataset_dir, \"TIF Files\")\n",
    "mask_dirs = [os.path.join(annotations_dir, mask_dir) for mask_dir in mission_list]\n",
    "mask_paths = [os.path.join(mask_dir, f\"{mission}.shp\") for mask_dir, mission in zip(mask_dirs, mission_list)]\n",
    "image_paths = [os.path.join(image_dir, f\"{mission}.tif\") for mission in mission_list]\n",
    "mask_paths_rasterized = [os.path.join(rasterized_dir, f\"{mission}_rasterized.tif\") for mission in mission_list]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:31.509813Z",
     "start_time": "2025-02-16T14:34:31.468064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "patch_size = 512\n",
    "stride = 256\n",
    "\n",
    "patch_output_dir = os.path.join(output_dir, f\"{patch_size}x{patch_size}\")\n",
    "os.makedirs(patch_output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Log setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:34.166945Z",
     "start_time": "2025-02-16T14:34:34.122026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sources.helpers.logger import LoggerHelper\n",
    "\n",
    "# Ensure the log directory exists\n",
    "logger_name = \"Satellite Segmentation Nepal\"\n",
    "log_dir=r\"../logs\"\n",
    "\n",
    "logger = LoggerHelper(logger_name=logger_name, log_dir=log_dir).logger\n",
    "logger.info(\"Logger setup complete.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-02-16 20:19:34,164 - Satellite Segmentation Nepal - INFO - Logger setup complete. [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/566460489.py:8]\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Utils Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:37.627006Z",
     "start_time": "2025-02-16T14:34:37.585661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sources.helpers.utils import UtilsHelper\n",
    "\n",
    "utils = UtilsHelper()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset preparation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rasterize the mask\n",
    "Rasterize the mask to the same projection and pixel resolution as the reference image. We have used the `gdal` library to rasterize the mask. The `gdal` library is a translator library for raster and vector geospatial data formats. It also includes a variety of useful command-line utilities for data translation and processing."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_file_path, mask_shape_file_path in zip(image_paths, mask_paths):\n",
    "    utils.rasterize_masks(image_file_path, mask_shape_file_path,rasterized_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create image and mask patches\n",
    "\n",
    "To prepare the satellite images and masks for segmentation, we first need to convert them into smaller patches. Here's how we can do it:\n",
    "\n",
    "1. Use the `create_patches()` function from the `utils` module.\n",
    "2. Pass the following parameters to the function:\n",
    "    - The file path of the satellite image in `.tif` format.\n",
    "    - The file path of the mask in `.shp` format.\n",
    "    - The output directory where the created patches will be saved.\n",
    "    - The patch size (we use the same value for height and width).\n",
    "    - The stride.\n",
    "    - A boundary that defines the area of interest.\n",
    "3. The function will iterate over the satellite image in patches of the specified size and stride.\n",
    "4. For each patch, the function will check if it intersects with any mask geometries (which are shapes such as polygons, lines, points, etc. that represent the features belonging to certain classes).\n",
    "5. If the patch intersects with any mask geometries, the function will create a patch mask by rasterizing the intersecting mask geometries. Otherwise, it will discard the patch.\n",
    "6. The function will save the patch and its corresponding patch mask to the output directory."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_mask_coverage = 0.1 # Percentage of minimum mask coverage in the patch\n",
    "\n",
    "# Iterate over image and mask paths\n",
    "for image_path, mask_path in zip(image_paths, mask_paths_rasterized):\n",
    "    utils.create_patches_categorical(\n",
    "        image_path=image_path,\n",
    "        mask_path=mask_path,\n",
    "        output_dir=patch_output_dir,\n",
    "        patch_size=patch_size,\n",
    "        stride=stride,\n",
    "        min_mask_coverage=min_mask_coverage\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split the dataset into training and validation sets\n",
    "This process organizes satellite image data and corresponding masks into `train`, `val`, and `test` directories while maintaining alignment between images and masks.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.split_dataset(patch_output_dir)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge the split dataset back into a unified dataset"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.merge_split_dataset(patch_output_dir)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualize a random image patch and its mask\n",
    "We can visualize a random patch and its mask using the `rasterio` and `matplotlib` libraries. The `rasterio` library is a Python package that provides a fast and direct way to work with raster data. We can use the `rasterio.open()` function to open the image and mask files. We can then use the `read()` function to read the image and mask data. We can then use the `imshow()` function from the `matplotlib.pyplot` module to display the image and the mask."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.visualize_random_patch(patch_output_dir)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dataset and data generator\n",
    "\n",
    "We define the dataset and data generator that will be used for training the model. To define the dataset and data generator, we can use the `NepalDataset` and `NepalDataGenerator` classes from the `dataset` module. This code takes a dataset and generates batches of data for training a deep learning model."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:43.726434Z",
     "start_time": "2025-02-16T14:34:43.673583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sources.helpers.generator import NepalDataset, NepalDataGenerator\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define dataset and data generator parameters\n",
    "dataset_split_dir = os.path.join(patch_output_dir, \"dataset_split\")\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets for train, val, and test splits\n",
    "train_dataset = NepalDataset(dataset_split_dir, split=\"train\", transform=transform)\n",
    "val_dataset = NepalDataset(dataset_split_dir, split=\"val\", transform=transform)\n",
    "test_dataset = NepalDataset(dataset_split_dir, split=\"test\", transform=transform)\n",
    "\n",
    "# Print dataset sizes\n",
    "logger.debug(f\"Train dataset size: {len(train_dataset)}\")\n",
    "logger.debug(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.debug(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Create data generators for each dataset\n",
    "train_data_generator = NepalDataGenerator(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_data_generator = NepalDataGenerator(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_data_generator = NepalDataGenerator(test_dataset, batch_size=batch_size, shuffle=False)  # Do not shuffle test data\n",
    "\n",
    "# Print data generator sizes\n",
    "logger.debug(f\"Train data generator size: {len(train_data_generator)}\")\n",
    "logger.debug(f\"Validation data generator size: {len(val_data_generator)}\")\n",
    "logger.debug(f\"Test data generator size: {len(test_data_generator)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m2025-02-16 20:19:43,724 - Satellite Segmentation Nepal - DEBUG - Train dataset size: 8210 [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/2807968097.py:18]\u001B[0m\n",
      "\u001B[94m2025-02-16 20:19:43,724 - Satellite Segmentation Nepal - DEBUG - Validation dataset size: 2737 [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/2807968097.py:19]\u001B[0m\n",
      "\u001B[94m2025-02-16 20:19:43,724 - Satellite Segmentation Nepal - DEBUG - Test dataset size: 2737 [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/2807968097.py:20]\u001B[0m\n",
      "\u001B[94m2025-02-16 20:19:43,724 - Satellite Segmentation Nepal - DEBUG - Train data generator size: 1642 [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/2807968097.py:28]\u001B[0m\n",
      "\u001B[94m2025-02-16 20:19:43,724 - Satellite Segmentation Nepal - DEBUG - Validation data generator size: 548 [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/2807968097.py:29]\u001B[0m\n",
      "\u001B[94m2025-02-16 20:19:43,724 - Satellite Segmentation Nepal - DEBUG - Test data generator size: 548 [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_34483/2807968097.py:30]\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualize data generator output image and mask patches\n",
    "\n",
    "This code visualizes the patches and patch masks that were created using the data generator. To visualize the patches and patch masks, we can use the `visualize()` function from `utils` module."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "no_of_images_to_show = 3  # Number of images to show from the batch\n",
    "# Select the data_generator to visualize (train/validation/test)\n",
    "selected_data_generator = train_data_generator  # Change to val_data_generator or test_data_generator as needed\n",
    "# Get the batch of images and masks\n",
    "utils.visualize_data_generator_output(\n",
    "    selected_data_generator=selected_data_generator,\n",
    "    no_of_images_to_show=no_of_images_to_show,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Definition\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:34:49.632604Z",
     "start_time": "2025-02-16T14:34:49.250817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sources.helpers.train import TrainingHelper\n",
    "\n",
    "# model_name= \"deeplabv3_resnet50\"\n",
    "# model_name = \"deeplabv3_mobilenet_v3_large\"\n",
    "model_name = \"deeplabv3_mobilenet_v3_large\"\n",
    "num_epochs = 100\n",
    "num_classes = 2\n",
    "loss_function = \"cross_entropy\"\n",
    "optimizer = \"adam\"\n",
    "\n",
    "training = TrainingHelper(\n",
    "    model_name = model_name,\n",
    "    num_classes = num_classes,\n",
    "    num_epochs = num_epochs,\n",
    "    loss_function = loss_function,\n",
    "    optimizer = optimizer,\n",
    "    train_data_generator = train_data_generator,\n",
    "    val_data_generator = val_data_generator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T14:37:30.666396Z",
     "start_time": "2025-02-16T14:37:29.109883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "\n",
    "try:\n",
    "    trained_model = training.train_model_with_mlflow(output_dir=output_dir)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error occurred during training: {e}\")\n",
    "finally:\n",
    "    mlflow.end_run()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m----> 4\u001B[0m     trained_model \u001B[38;5;241m=\u001B[39m \u001B[43mtraining\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model_with_mlflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m      6\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError occurred during training: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Masters Thesis/Projects/aerial-satellite-imagery-segmentation-nepal/sources/helpers/train.py:122\u001B[0m, in \u001B[0;36mTrainingHelper.train_model_with_mlflow\u001B[0;34m(self, output_dir)\u001B[0m\n\u001B[1;32m    119\u001B[0m masks \u001B[38;5;241m=\u001B[39m masks\u001B[38;5;241m.\u001B[39mlong()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    123\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(outputs, masks)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;66;03m# Backward pass and optimization\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torchvision/models/segmentation/_utils.py:27\u001B[0m, in \u001B[0;36m_SimpleSegmentationModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     25\u001B[0m result \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m     26\u001B[0m x \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m---> 27\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39minterpolate(x, size\u001B[38;5;241m=\u001B[39minput_shape, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     29\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m x\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torchvision/models/segmentation/deeplabv3.py:111\u001B[0m, in \u001B[0;36mASPP.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    109\u001B[0m _res \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs:\n\u001B[0;32m--> 111\u001B[0m     _res\u001B[38;5;241m.\u001B[39mappend(\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    112\u001B[0m res \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(_res, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproject(res)\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torchvision/models/segmentation/deeplabv3.py:82\u001B[0m, in \u001B[0;36mASPPPooling.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m     81\u001B[0m     x \u001B[38;5;241m=\u001B[39m mod(x)\n\u001B[0;32m---> 82\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbilinear\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/aerial-satellite-imagery-segmentation-nepal/lib/python3.10/site-packages/torch/nn/functional.py:4020\u001B[0m, in \u001B[0;36minterpolate\u001B[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001B[0m\n\u001B[1;32m   4014\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mare_deterministic_algorithms_enabled() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mis_cuda:\n\u001B[1;32m   4015\u001B[0m             \u001B[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001B[39;00m\n\u001B[1;32m   4016\u001B[0m             \u001B[38;5;66;03m# importlib is required because the import cannot be top level\u001B[39;00m\n\u001B[1;32m   4017\u001B[0m             \u001B[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001B[39;00m\n\u001B[1;32m   4018\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch._decomp.decompositions\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mupsample_bilinear2d_vec(\n\u001B[1;32m   4019\u001B[0m                 \u001B[38;5;28minput\u001B[39m, output_size, align_corners, scale_factors)\n\u001B[0;32m-> 4020\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsample_bilinear2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_factors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4021\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   4022\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m align_corners \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
