{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Satellite Image Segmentation of Nepal\n",
    "**Prepared By:** Ajeeb Rimal | M. Tech. AI | Kathmandu University"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Directory definitions and setup\n",
    "We have defined the directory paths for the dataset, image, and mask files. We have also defined and created the output directory where the patches will be saved.Additionally we have defined the patch size, stride, and boundary for the patches. The boundary is defined as a list of four values: [min_x, min_y, max_x, max_y] which represent the minimum and maximum x and y coordinates of the area of interest, respectively. We have used the `os` library to create the output directory if it does not exist."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import os",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mission_list = [\"Mission 1\", \"Mission 2\", \"Mission 3\", \"Mission 4\", \"Mission 5\"]\n",
    "dataset_dir = r\"/Users/ajeebrimal/Documents/Masters Thesis/Datasets/Rupandehi Data\"\n",
    "annotations_dir = os.path.join(dataset_dir, \"Annotations\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_dir = r\"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "rasterized_dir = os.path.join(output_dir, \"rasterized_outputs\")\n",
    "os.makedirs(rasterized_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_dir = os.path.join(dataset_dir, \"TIF Files\")\n",
    "mask_dirs = [os.path.join(annotations_dir, mask_dir) for mask_dir in mission_list]\n",
    "mask_paths = [os.path.join(mask_dir, f\"{mission}.shp\") for mask_dir, mission in zip(mask_dirs, mission_list)]\n",
    "image_paths = [os.path.join(image_dir, f\"{mission}.tif\") for mission in mission_list]\n",
    "mask_paths_rasterized = [os.path.join(rasterized_dir, f\"{mission}_rasterized.tif\") for mission in mission_list]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "patch_size = 512\n",
    "stride = 256\n",
    "\n",
    "patch_output_dir = os.path.join(output_dir, f\"{patch_size}x{patch_size}\")\n",
    "os.makedirs(patch_output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Log setup"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sources.helpers.logger import LoggerHelper\n",
    "\n",
    "# Ensure the log directory exists\n",
    "logger_name = \"Satellite Segmentation Nepal\"\n",
    "log_dir=r\"../logs\"\n",
    "\n",
    "logger = LoggerHelper(logger_name=logger_name, log_dir=log_dir).logger\n",
    "logger.info(\"Logger setup complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Utils Setup"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sources.helpers.utils import UtilsHelper\n",
    "\n",
    "utils = UtilsHelper()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset preparation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rasterize the mask\n",
    "Rasterize the mask to the same projection and pixel resolution as the reference image. We have used the `gdal` library to rasterize the mask. The `gdal` library is a translator library for raster and vector geospatial data formats. It also includes a variety of useful command-line utilities for data translation and processing."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_file_path, mask_shape_file_path in zip(image_paths, mask_paths):\n",
    "    utils.rasterize_masks(image_file_path, mask_shape_file_path,rasterized_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create image and mask patches\n",
    "\n",
    "To prepare the satellite images and masks for segmentation, we first need to convert them into smaller patches. Here's how we can do it:\n",
    "\n",
    "1. Use the `create_patches()` function from the `utils` module.\n",
    "2. Pass the following parameters to the function:\n",
    "    - The file path of the satellite image in `.tif` format.\n",
    "    - The file path of the mask in `.shp` format.\n",
    "    - The output directory where the created patches will be saved.\n",
    "    - The patch size (we use the same value for height and width).\n",
    "    - The stride.\n",
    "    - A boundary that defines the area of interest.\n",
    "3. The function will iterate over the satellite image in patches of the specified size and stride.\n",
    "4. For each patch, the function will check if it intersects with any mask geometries (which are shapes such as polygons, lines, points, etc. that represent the features belonging to certain classes).\n",
    "5. If the patch intersects with any mask geometries, the function will create a patch mask by rasterizing the intersecting mask geometries. Otherwise, it will discard the patch.\n",
    "6. The function will save the patch and its corresponding patch mask to the output directory."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_mask_coverage = 0.1 # Percentage of minimum mask coverage in the patch\n",
    "\n",
    "# Iterate over image and mask paths\n",
    "for image_path, mask_path in zip(image_paths, mask_paths_rasterized):\n",
    "    utils.create_patches_categorical(\n",
    "        image_path=image_path,\n",
    "        mask_path=mask_path,\n",
    "        output_dir=patch_output_dir,\n",
    "        patch_size=patch_size,\n",
    "        stride=stride,\n",
    "        min_mask_coverage=min_mask_coverage\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split the dataset into training and validation sets\n",
    "This process organizes satellite image data and corresponding masks into `train`, `val`, and `test` directories while maintaining alignment between images and masks.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.split_dataset(patch_output_dir)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge the split dataset back into a unified dataset"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.merge_split_dataset(patch_output_dir)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualize a random image patch and its mask\n",
    "We can visualize a random patch and its mask using the `rasterio` and `matplotlib` libraries. The `rasterio` library is a Python package that provides a fast and direct way to work with raster data. We can use the `rasterio.open()` function to open the image and mask files. We can then use the `read()` function to read the image and mask data. We can then use the `imshow()` function from the `matplotlib.pyplot` module to display the image and the mask."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.visualize_random_patch(patch_output_dir)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dataset and data generator\n",
    "\n",
    "We define the dataset and data generator that will be used for training the model. To define the dataset and data generator, we can use the `NepalDataset` and `NepalDataGenerator` classes from the `dataset` module. This code takes a dataset and generates batches of data for training a deep learning model."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sources.helpers.generator import NepalDataset, NepalDataGenerator\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define dataset and data generator parameters\n",
    "dataset_split_dir = os.path.join(patch_output_dir, \"dataset_split\")\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets for train, val, and test splits\n",
    "train_dataset = NepalDataset(dataset_split_dir, split=\"train\", transform=transform)\n",
    "val_dataset = NepalDataset(dataset_split_dir, split=\"val\", transform=transform)\n",
    "test_dataset = NepalDataset(dataset_split_dir, split=\"test\", transform=transform)\n",
    "\n",
    "# Print dataset sizes\n",
    "logger.debug(f\"Train dataset size: {len(train_dataset)}\")\n",
    "logger.debug(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.debug(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Create data generators for each dataset\n",
    "train_data_generator = NepalDataGenerator(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_data_generator = NepalDataGenerator(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_data_generator = NepalDataGenerator(test_dataset, batch_size=batch_size, shuffle=False)  # Do not shuffle test data\n",
    "\n",
    "# Print data generator sizes\n",
    "logger.debug(f\"Train data generator size: {len(train_data_generator)}\")\n",
    "logger.debug(f\"Validation data generator size: {len(val_data_generator)}\")\n",
    "logger.debug(f\"Test data generator size: {len(test_data_generator)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualize data generator output image and mask patches\n",
    "\n",
    "This code visualizes the patches and patch masks that were created using the data generator. To visualize the patches and patch masks, we can use the `visualize()` function from `utils` module."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "no_of_images_to_show = 3  # Number of images to show from the batch\n",
    "# Select the data_generator to visualize (train/validation/test)\n",
    "selected_data_generator = train_data_generator  # Change to val_data_generator or test_data_generator as needed\n",
    "# Get the batch of images and masks\n",
    "utils.visualize_data_generator_output(\n",
    "    selected_data_generator=selected_data_generator,\n",
    "    no_of_images_to_show=no_of_images_to_show,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Definition\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sources.helpers.train import TrainingHelper\n",
    "\n",
    "# model_name= \"deeplabv3_resnet50\"\n",
    "# model_name = \"deeplabv3_mobilenet_v3_large\"\n",
    "model_name = \"deeplabv3_mobilenet_v3_large\"\n",
    "num_epochs = 100\n",
    "num_classes = 2\n",
    "loss_function = \"cross_entropy\"\n",
    "optimizer = \"adam\"\n",
    "\n",
    "training = TrainingHelper(\n",
    "    model_name = model_name,\n",
    "    num_classes = num_classes,\n",
    "    num_epochs = num_epochs,\n",
    "    loss_function = loss_function,\n",
    "    optimizer = optimizer,\n",
    "    train_data_generator = train_data_generator,\n",
    "    val_data_generator = val_data_generator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "\n",
    "try:\n",
    "    trained_model = training.train_model_with_mlflow(output_dir=output_dir)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error occurred during training: {e}\")\n",
    "finally:\n",
    "    mlflow.end_run()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
