{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Image Segmentation of Nepal\n",
    "**Prepared By:** Ajeeb Rimal | M. Tech. AI | Kathmandu University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T18:34:22.087748Z",
     "start_time": "2025-01-12T18:34:19.820484Z"
    }
   },
   "source": [
    "import cv2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "from rasterio.features import shapes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from osgeo import ogr, gdal\n",
    "from torchvision.transforms import transforms\n",
    "import geopandas as gpd\n",
    "\n",
    "from generator import NepalDataset, NepalDataGenerator\n",
    "from pan import PAN\n",
    "from train import train_model\n",
    "from utils import create_patches, visualize,rasterize_masks,setup_logger"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Logger Setup"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory definitions\n",
    "We have defined the directory paths for the dataset, image, and mask files. We have also defined and created the output directory where the patches will be saved.Additionally we have defined the patch size, stride, and boundary for the patches. The boundary is defined as a list of four values: [min_x, min_y, max_x, max_y] which represent the minimum and maximum x and y coordinates of the area of interest, respectively. We have used the `os` library to create the output directory if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T18:34:22.108851Z",
     "start_time": "2025-01-12T18:34:22.091399Z"
    }
   },
   "source": [
    "mission_list = ['Mission 1', 'Mission 2', 'Mission 3', 'Mission 4', 'Mission 5']\n",
    "dataset_dir = os.path.join('/', 'Users', 'ajeebrimal', 'Documents', 'Masters Thesis', 'Datasets', 'Rupandehi Data')\n",
    "annotations_dir = os.path.join(dataset_dir, 'Annotations')\n",
    "image_dir = os.path.join(dataset_dir, 'TIF Files') \n",
    "mask_dirs = [os.path.join(annotations_dir, mask_dir) for mask_dir in mission_list]\n",
    "mask_paths = [os.path.join(mask_dir, f'{mission}.shp') for mask_dir, mission in zip(mask_dirs, mission_list)]\n",
    "image_paths = [os.path.join(image_dir, f'{mission}.tif') for mission in mission_list]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T18:34:22.839137Z",
     "start_time": "2025-01-12T18:34:22.139561Z"
    }
   },
   "source": [
    "output_dir = os.path.join('.', 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "rasterized_dir = os.path.join(output_dir, 'rasterized_outputs')\n",
    "os.makedirs(rasterized_dir, exist_ok=True)\n",
    "\n",
    "mask_paths_rasterized = [os.path.join(rasterized_dir, f'{mission}_rasterized.tif') for mission in mission_list]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T18:34:23.051075Z",
     "start_time": "2025-01-12T18:34:23.033596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "patch_size = 512\n",
    "stride = 256\n",
    "boundary = [3053710.461731, 751158.377075, 3055429.699707, 753175.112122]\n",
    "\n",
    "patch_output_dir = os.path.join(output_dir, f\"{patch_size}x{patch_size}\")\n",
    "os.makedirs(patch_output_dir, exist_ok=True)\n",
    "\n",
    "labels_output_dir = os.path.join(patch_output_dir, 'labels')\n",
    "os.makedirs(labels_output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T18:34:23.094455Z",
     "start_time": "2025-01-12T18:34:23.063907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure the log directory exists\n",
    "log_dir = os.path.join('.', 'logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logger = setup_logger(log_dir)\n",
    "logger.info(\"Logger setup complete.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-01-13 00:19:23,080 - ./logs - INFO - Logger setup complete. [in /var/folders/wd/hjtm8j014ssf90kvk6rjl1pw0000gn/T/ipykernel_93984/83787627.py:6]\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Rasterize the mask\n",
    "Rasterize the mask to the same projection and pixel resolution as the reference image. We have used the `gdal` library to rasterize the mask. The `gdal` library is a translator library for raster and vector geospatial data formats. It also includes a variety of useful command-line utilities for data translation and processing."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "# Use ThreadPoolExecutor to run rasterization in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(rasterize_masks, image_file_path, mask_shape_file_path,rasterized_dir,logger) for image_file_path, mask_shape_file_path in zip(image_paths, mask_paths)]\n",
    "    concurrent.futures.wait(futures)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the image and its rasterized mask\n",
    "We can visualize the image and the rasterized mask using the `matplotlib` library. The `matplotlib` library is a plotting library for the Python programming language and its numerical mathematics extension, NumPy. We can use the `imshow()` function from the `matplotlib.pyplot` module to display the image and the mask."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Open the rasters\n",
    "# with rasterio.open(image_paths[0]) as raster1:\n",
    "#     temp_img = raster1.read()  # Read raster1 into numpy array\n",
    "# \n",
    "# with rasterio.open(mask_paths_rasterized[0]) as raster2:\n",
    "#     temp_mask = raster2.read(1)  # Read raster2 into numpy array\n",
    "# \n",
    "# labels, count = np.unique(temp_mask, return_counts=True)  #Check for each channel. All channels are identical\n",
    "# print('Unique values in mask: ', labels)\n",
    "# print('Counts of unique values: ', count)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # The image data read by Rasterio is in (bands, rows, cols) order\n",
    "# # Convert the image data to (rows, cols, bands) order for visualization\n",
    "# transposed_image = temp_img.transpose((1, 2, 0)).astype('float64')\n",
    "# \n",
    "# # Scale the image data to be between 0 and 1 for better visualization\n",
    "# transposed_image -= transposed_image.min()\n",
    "# transposed_image /= transposed_image.max()\n",
    "# \n",
    "# plt.figure(figsize=(12, 8))\n",
    "# # Plot raster1\n",
    "# plt.imshow(temp_img, interpolation='nearest')\n",
    "# # Overlay raster2, make sure to use the same extent \n",
    "# plt.imshow(temp_mask, interpolation='nearest', cmap='tab10', alpha=0.4)\n",
    "# plt.show()\n",
    "# \n",
    "# print('Image shape: ', temp_img.shape)\n",
    "# print('Mask shape: ', temp_mask.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image and mask patches\n",
    "\n",
    "To prepare the satellite images and masks for segmentation, we first need to convert them into smaller patches. Here's how we can do it:\n",
    "\n",
    "1. Use the `create_patches()` function from the `utils` module.\n",
    "2. Pass the following parameters to the function:\n",
    "    - The file path of the satellite image in `.tif` format.\n",
    "    - The file path of the mask in `.shp` format.\n",
    "    - The output directory where the created patches will be saved.\n",
    "    - The patch size (we use the same value for height and width).\n",
    "    - The stride.\n",
    "    - A boundary that defines the area of interest.\n",
    "3. The function will iterate over the satellite image in patches of the specified size and stride.\n",
    "4. For each patch, the function will check if it intersects with any mask geometries (which are shapes such as polygons, lines, points, etc. that represent the features belonging to certain classes).\n",
    "5. If the patch intersects with any mask geometries, the function will create a patch mask by rasterizing the intersecting mask geometries. Otherwise, it will discard the patch.\n",
    "6. The function will save the patch and its corresponding patch mask to the output directory."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T18:36:22.028212Z",
     "start_time": "2025-01-12T18:34:45.973796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import create_patches_one_hot, create_patches_categorical\n",
    "\n",
    "min_mask_coverage=0.1 # Percentage of minimum mask coverage in the patch\n",
    "\n",
    "# Iterate over image and mask paths\n",
    "for image_path, mask_path in zip(image_paths, mask_paths_rasterized):\n",
    "    # Pass `outer_pbar` to the inner function\n",
    "    create_patches_categorical(\n",
    "        image_path=image_path,\n",
    "        mask_path=mask_path,\n",
    "        output_dir=patch_output_dir,\n",
    "        patch_size=patch_size,\n",
    "        stride=stride,\n",
    "        logger=logger,\n",
    "        min_mask_coverage=min_mask_coverage\n",
    "    )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patches for Mission 1:   0%|          | 0/18875 [00:00<?, ?patch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77e41f9bdc1e43bca5282d4c38b9c036"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-01-13 00:20:10,558 - ./logs - INFO - Completed: 'Mission 1' with 18875 patches processed, 2903 patches saved [in /Users/ajeebrimal/Documents/Masters Thesis/Projects/aerial-satellite-imagery-segmentation-nepal/utils.py:423]\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patches for Mission 2:   0%|          | 0/14940 [00:00<?, ?patch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab3905981d0f4a88944e995e2c41644b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-01-13 00:20:28,778 - ./logs - INFO - Completed: 'Mission 2' with 14940 patches processed, 2465 patches saved [in /Users/ajeebrimal/Documents/Masters Thesis/Projects/aerial-satellite-imagery-segmentation-nepal/utils.py:423]\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patches for Mission 3:   0%|          | 0/14762 [00:00<?, ?patch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "134914349e6c48b6b97a42150df46256"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-01-13 00:20:55,760 - ./logs - INFO - Completed: 'Mission 3' with 14762 patches processed, 4962 patches saved [in /Users/ajeebrimal/Documents/Masters Thesis/Projects/aerial-satellite-imagery-segmentation-nepal/utils.py:423]\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patches for Mission 4:   0%|          | 0/9694 [00:00<?, ?patch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d121fcc132e478a83515fd3efee681d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-01-13 00:21:07,531 - ./logs - INFO - Completed: 'Mission 4' with 9694 patches processed, 1547 patches saved [in /Users/ajeebrimal/Documents/Masters Thesis/Projects/aerial-satellite-imagery-segmentation-nepal/utils.py:423]\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patches for Mission 5:   0%|          | 0/10088 [00:00<?, ?patch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2421f3bf644496b93b045193a41fa98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m2025-01-13 00:21:21,964 - ./logs - INFO - Completed: 'Mission 5' with 10088 patches processed, 1807 patches saved [in /Users/ajeebrimal/Documents/Masters Thesis/Projects/aerial-satellite-imagery-segmentation-nepal/utils.py:423]\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a random image patch and its mask\n",
    "We can visualize a random patch and its mask using the `rasterio` and `matplotlib` libraries. The `rasterio` library is a Python package that provides a fast and direct way to work with raster data. We can use the `rasterio.open()` function to open the image and mask files. We can then use the `read()` function to read the image and mask data. We can then use the `imshow()` function from the `matplotlib.pyplot` module to display the image and the mask."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get list of all image files in the directory\n",
    "image_files = [f for f in os.listdir(patch_output_dir + \"/images\") if f.endswith('.tiff')]\n",
    "\n",
    "# Select a random image file\n",
    "random_image_file = random.choice(image_files)\n",
    "\n",
    "# Construct the full paths to the image and mask files\n",
    "temp_image_path = os.path.join(patch_output_dir, \"images\", random_image_file)\n",
    "temp_mask_path = os.path.join(patch_output_dir, \"masks\", random_image_file.replace('.tiff', '_mask.tiff'))\n",
    "\n",
    "# Open the image and mask files using Rasterio\n",
    "with rasterio.open(temp_image_path) as src:\n",
    "    image = src.read().astype(float)\n",
    "    image_transform = src.transform\n",
    "\n",
    "with rasterio.open(temp_mask_path) as src:\n",
    "    mask = src.read()\n",
    "    mask_transform = src.transform\n",
    "\n",
    "# The image data read by Rasterio is in (bands, rows, cols) order\n",
    "# Convert the image data to (rows, cols, bands) order for visualization\n",
    "transposed_image = image.transpose((1, 2, 0))\n",
    "\n",
    "# Scale the image data to be between 0 and 1 for better visualization\n",
    "transposed_image -= transposed_image.min()\n",
    "transposed_image /= transposed_image.max()\n",
    "\n",
    "# Create plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "\n",
    "# Display the image\n",
    "ax[0].imshow(transposed_image)\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "# Display the mask\n",
    "ax[1].imshow(mask[0], cmap='gray')\n",
    "ax[1].set_title(\"Mask\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Image shape: ', image.shape)\n",
    "print('Mask shape: ', mask.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and data generator\n",
    "\n",
    "We define the dataset and data generator that will be used for training the model. To define the dataset and data generator, we can use the `NepalDataset` and `NepalDataGenerator` classes from the `dataset` module. This code takes a dataset and generates batches of data for training a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_path = patch_output_dir\n",
    "in_channels = 4\n",
    "num_classes = 3\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = NepalDataset(data_path, transform=transform)\n",
    "print(f\"Dataset size: {format(len(dataset))}\")\n",
    "data_generator = NepalDataGenerator(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "print(f\"Data generator size: {format(len(data_generator))}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data generator output image and mask patches\n",
    "\n",
    "This code visualizes the patches and patch masks that were created using the data generator. To visualize the patches and patch masks, we can use the `visualize()` function from `utils` module."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "no_of_images_to_show = 3  # Number of images to show from the batch\n",
    "\n",
    "images, masks = data_generator.__next__()  # Get the batch of images and masks\n",
    "\n",
    "if no_of_images_to_show > batch_size:\n",
    "    no_of_images_to_show = batch_size\n",
    "\n",
    "for i in range(0, no_of_images_to_show):\n",
    "    image = images[i].permute(1, 2, 0).numpy()  # Access individual image and convert to numpy array\n",
    "    mask = masks[i].squeeze().numpy()  # Access individual mask and convert to numpy array\n",
    "    visualize(image, mask)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pan_model = PAN(in_channels)\n",
    "train_model(pan_model, data_generator)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo V8 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import tifffile\n",
    "\n",
    "\n",
    "def mask_to_polygons(img_path, mask_path):\n",
    "    '''\n",
    "    Convierte una máscara de imagen en polígonos. Devuelve dos listas:\n",
    "    - Lista de polígonos de shapely sin normalizar\n",
    "    - Lista de polígonos de shapely normalizados (coordenadas entre 0 y 1)\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Ruta al archivo de imagen original.\n",
    "        mask_path (str): Ruta al archivo de la máscara en escala de grises.\n",
    "    '''\n",
    "\n",
    "    mask = tifffile.imread(mask_path)\n",
    "\n",
    "    # mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Calcula los contornos \n",
    "    mask = mask.astype(bool)\n",
    "    #contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # convertimos los contornos a polígonos de Label Studio\n",
    "    polygons = []\n",
    "    normalized_polygons = []\n",
    "    for contour in contours:\n",
    "\n",
    "        # Lo meto en un try porque la extraccion de polígonos que hace el opencv a partir de la máscara\n",
    "        # a veces genera polígonos de menos de 4 vértices, que no tiene sentido por no ser cerrados, \n",
    "        # provocando que falle al convertir a polígno de shapely\n",
    "\n",
    "        try:\n",
    "            polygon = contour.reshape(-1, 2).tolist()\n",
    "\n",
    "            # normalizamos las coordenadas entre 0 y 1 porque así lo requiere YOLOv8\n",
    "            normalized_polygon = [[round(coord[0] / mask.shape[1], 4), round(coord[1] / mask.shape[0], 4)] for coord in\n",
    "                                  polygon]\n",
    "\n",
    "            # Convertimos a objeto poligono de shapely (sin normalizar)\n",
    "            polygon_shapely = Polygon(polygon)\n",
    "            simplified_polygon = polygon_shapely.simplify(0.85, preserve_topology=True)\n",
    "            polygons.append(simplified_polygon)\n",
    "\n",
    "            # normalizdos\n",
    "            normalized_polygons.append(Polygon(normalized_polygon))\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return polygons, normalized_polygons"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def mask_to_polygons_per_class(img_path, mask_path):\n",
    "    # Map grayscale mask values to your class indices\n",
    "    class_mapping = {0: 0, 1: 1, 2: 2}\n",
    "\n",
    "    mask = tifffile.imread(mask_path)\n",
    "\n",
    "    polygons_per_class = {}\n",
    "    for mask_value in np.unique(mask):\n",
    "        # Look up class index using mask value, if no mapping is found then continue\n",
    "        class_index = class_mapping.get(mask_value)\n",
    "        if class_index is None:\n",
    "            continue\n",
    "\n",
    "        class_mask = np.where(mask == mask_value, 1, 0).astype(np.uint8)\n",
    "\n",
    "        contours, _ = cv2.findContours(class_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        polygons = []\n",
    "        for contour in contours:\n",
    "            try:\n",
    "                polygon = contour.reshape(-1, 2).tolist()\n",
    "\n",
    "                normalized_polygon = [\n",
    "                    [round(coord[0] / mask.shape[1], 4), round(coord[1] / mask.shape[0], 4)]\n",
    "                    for coord in polygon\n",
    "                ]\n",
    "\n",
    "                if class_index not in polygons_per_class:\n",
    "                    polygons_per_class[class_index] = []\n",
    "                polygons_per_class[class_index].append(Polygon(normalized_polygon))\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return polygons_per_class\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "input_dir = os.path.join(patch_output_dir, 'masks')\n",
    "output_dir = labels_output_dir\n",
    "\n",
    "for j in os.listdir(input_dir):\n",
    "    image_path = os.path.join(input_dir, j)\n",
    "    polygons, normalized_polygons = mask_to_polygons(image_path, image_path)  # Separate lists for each class\n",
    "\n",
    "    # print the polygons\n",
    "    file_name_without_ext = os.path.splitext(j)[0]\n",
    "    if file_name_without_ext.endswith('_mask'):\n",
    "        file_name_without_ext = file_name_without_ext[:-5]\n",
    "\n",
    "    with open('{}.txt'.format(os.path.join(output_dir, file_name_without_ext)), 'w') as f:\n",
    "        for class_label in range(3):\n",
    "            for polygon in normalized_polygons:\n",
    "                f.write('{} '.format(class_label))  # Add class label at the beginning of each line\n",
    "                if isinstance(polygon, Polygon):\n",
    "                    x, y = polygon.exterior.xy\n",
    "                    for i in range(len(x)):\n",
    "                        f.write('{} {}\\t'.format(x[i], y[i]))\n",
    "                f.write('\\n')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "input_dir = os.path.join(patch_output_dir, 'masks')\n",
    "output_dir = labels_output_dir\n",
    "\n",
    "\n",
    "for j in os.listdir(input_dir):\n",
    "    image_path = os.path.join(input_dir, j)\n",
    "    polygons_per_class = mask_to_polygons_per_class(image_path, image_path)\n",
    "\n",
    "    # print the polygons\n",
    "    file_name_without_ext = os.path.splitext(j)[0]\n",
    "    if file_name_without_ext.endswith('_mask'):\n",
    "        file_name_without_ext = file_name_without_ext[:-5]\n",
    "    \n",
    "    with open('{}.txt'.format(os.path.join(output_dir, file_name_without_ext)), 'w') as f:\n",
    "        for class_label, polygons in polygons_per_class.items():\n",
    "            for polygon in polygons:\n",
    "                f.write('{} '.format(class_label))  # Add class label at the beginning of each line\n",
    "                x, y = polygon.exterior.xy\n",
    "                for i in range(len(x)):\n",
    "                    f.write('{} {}\\t'.format(x[i], y[i]))\n",
    "                f.write('\\n')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_dataset_into_train_val_test(input_folder, output_folder, ratio=(0.7, 0.15, 0.15)):\n",
    "    assert sum(ratio) == 1, \"Ratios must add up to 1.\"\n",
    "\n",
    "    # Get all file names in the input folder\n",
    "    all_files = os.listdir(input_folder)\n",
    "    np.random.shuffle(all_files)\n",
    "\n",
    "    num_files = len(all_files)\n",
    "    train_files = all_files[:int(num_files * ratio[0])]\n",
    "    val_files = all_files[int(num_files * ratio[0]):int(num_files * (ratio[0] + ratio[1]))]\n",
    "    test_files = all_files[int(num_files * (ratio[0] + ratio[1])):]\n",
    "\n",
    "    # Create output directories\n",
    "    for dir in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_folder, dir), exist_ok=True)\n",
    "\n",
    "    # Move files to respective directories\n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(input_folder, file), os.path.join(output_folder, 'train', file))\n",
    "\n",
    "    for file in val_files:\n",
    "        shutil.move(os.path.join(input_folder, file), os.path.join(output_folder, 'val', file))\n",
    "\n",
    "    for file in test_files:\n",
    "        shutil.move(os.path.join(input_folder, file), os.path.join(output_folder, 'test', file))\n",
    "\n",
    "\n",
    "directories = ['images', 'labels', 'masks']\n",
    "patch_output_directory = patch_output_dir\n",
    "\n",
    "for directory in directories:\n",
    "    input_folder = os.path.join(patch_output_directory, directory)\n",
    "    output_folder = os.path.join(patch_output_directory, directory)\n",
    "    split_dataset_into_train_val_test(input_folder, output_folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all files in the subfolders to the main folder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_all_files(directory):\n",
    "    main_folders = ['images', 'labels', 'masks']\n",
    "    subfolders = ['test', 'train', 'val']\n",
    "\n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(directory, main_folder)\n",
    "\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "\n",
    "            # merge all files in subfolder to main_folder\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                shutil.move(os.path.join(subfolder_path, filename), main_folder_path)\n",
    "\n",
    "            # remove subfolder\n",
    "            shutil.rmtree(subfolder_path)\n",
    "# function call\n",
    "merge_all_files(patch_output_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8m-seg.pt')\n",
    "\n",
    "model.train(data='config.yaml', epochs=100, imgsz=512, single_cls=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = 'runs/segment/train13/weights/best.pt'\n",
    "\n",
    "image_path = 'output/2048x2048/images/patch_598.tiff'\n",
    "\n",
    "img= cv2.imread(image_path)\n",
    "H, W, _ = img.shape\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "results = model(img)\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename='result.jpg')  # save to disk\n",
    "# \n",
    "# for result in results:\n",
    "#     for j,mask in enumerate(result.masks.data):\n",
    "#         mask=mask.cpu().numpy()*255\n",
    "#         mask=cv2.resize(mask, (W,H))\n",
    "#         visualize(img,mask)\n",
    "#         print(f\"Class of mask {j}: {result.masks.data.names[j]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "mask_path = './output/512x512/masks/test/patch_3361_mask.jpg'\n",
    "mask = tifffile.imread(mask_path)\n",
    "unique_values = np.unique(mask)\n",
    "print(unique_values)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
